{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a8a366-be50-4d08-b4df-5546c012b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-23 00:13:42,257] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Enabling DeepSpeed FP16. Model parameters and inputs will be cast to `float16`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.266709327697754 seconds\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ViT              | 17.9 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "17.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.9 M    Total params\n",
      "71.584    Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('val_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:439: It is recommended to use `self.log('train_acc', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "Epoch 1:\n",
      "Training Loss: 4.6291, Training Accuracy: 0.0125\n",
      "Validation Loss: 4.4276, Validation Accuracy: 0.0289\n",
      "Epoch 2:\n",
      "Training Loss: 4.4994, Training Accuracy: 0.0197\n",
      "Validation Loss: 4.3537, Validation Accuracy: 0.0346\n",
      "Epoch 3:\n",
      "Training Loss: 4.3942, Training Accuracy: 0.0301\n",
      "Validation Loss: 4.3050, Validation Accuracy: 0.0406\n",
      "Epoch 4:\n",
      "Training Loss: 4.3145, Training Accuracy: 0.0362\n",
      "Validation Loss: 4.2131, Validation Accuracy: 0.0509\n",
      "Epoch 5:\n",
      "Training Loss: 4.2568, Training Accuracy: 0.0444\n",
      "Validation Loss: 4.1063, Validation Accuracy: 0.0642\n",
      "Epoch 6:\n",
      "Training Loss: 4.1554, Training Accuracy: 0.0600\n",
      "Validation Loss: 4.0960, Validation Accuracy: 0.0660\n",
      "Epoch 7:\n",
      "Training Loss: 4.1219, Training Accuracy: 0.0652\n",
      "Validation Loss: 3.9950, Validation Accuracy: 0.0815\n",
      "Epoch 8:\n",
      "Training Loss: 4.0370, Training Accuracy: 0.0756\n",
      "Validation Loss: 3.9248, Validation Accuracy: 0.0897\n",
      "Epoch 9:\n",
      "Training Loss: 3.9562, Training Accuracy: 0.0876\n",
      "Validation Loss: 3.8809, Validation Accuracy: 0.1004\n",
      "Epoch 10:\n",
      "Training Loss: 3.8862, Training Accuracy: 0.0976\n",
      "Validation Loss: 3.8044, Validation Accuracy: 0.1105\n",
      "Epoch 11:\n",
      "Training Loss: 3.8180, Training Accuracy: 0.1055\n",
      "Validation Loss: 3.7473, Validation Accuracy: 0.1175\n",
      "Epoch 12:\n",
      "Training Loss: 3.7883, Training Accuracy: 0.1116\n",
      "Validation Loss: 3.6974, Validation Accuracy: 0.1205\n",
      "Epoch 13:\n",
      "Training Loss: 3.7085, Training Accuracy: 0.1215\n",
      "Validation Loss: 3.7379, Validation Accuracy: 0.1218\n",
      "Epoch 14:\n",
      "Training Loss: 3.6885, Training Accuracy: 0.1274\n",
      "Validation Loss: 3.6554, Validation Accuracy: 0.1345\n",
      "Epoch 15:\n",
      "Training Loss: 3.6575, Training Accuracy: 0.1325\n",
      "Validation Loss: 3.5620, Validation Accuracy: 0.1430\n",
      "Epoch 16:\n",
      "Training Loss: 3.5727, Training Accuracy: 0.1433\n",
      "Validation Loss: 3.5650, Validation Accuracy: 0.1488\n",
      "Epoch 17:\n",
      "Training Loss: 3.5574, Training Accuracy: 0.1485\n",
      "Validation Loss: 3.5338, Validation Accuracy: 0.1562\n",
      "Epoch 18:\n",
      "Training Loss: 3.5172, Training Accuracy: 0.1543\n",
      "Validation Loss: 3.4366, Validation Accuracy: 0.1710\n",
      "Epoch 19:\n",
      "Training Loss: 3.4373, Training Accuracy: 0.1688\n",
      "Validation Loss: 3.3962, Validation Accuracy: 0.1802\n",
      "Epoch 20:\n",
      "Training Loss: 3.3754, Training Accuracy: 0.1784\n",
      "Validation Loss: 3.3387, Validation Accuracy: 0.1905\n",
      "Epoch 21:\n",
      "Training Loss: 3.3488, Training Accuracy: 0.1838\n",
      "Validation Loss: 3.2758, Validation Accuracy: 0.1997\n",
      "Epoch 22:\n",
      "Training Loss: 3.2598, Training Accuracy: 0.1983\n",
      "Validation Loss: 3.3505, Validation Accuracy: 0.1899\n",
      "Epoch 23:\n",
      "Training Loss: 3.2501, Training Accuracy: 0.2029\n",
      "Validation Loss: 3.2866, Validation Accuracy: 0.1958\n",
      "Epoch 24:\n",
      "Training Loss: 3.2654, Training Accuracy: 0.1982\n",
      "Validation Loss: 3.1931, Validation Accuracy: 0.2109\n",
      "Epoch 25:\n",
      "Training Loss: 3.1713, Training Accuracy: 0.2150\n",
      "Validation Loss: 3.2285, Validation Accuracy: 0.2131\n",
      "Epoch 26:\n",
      "Training Loss: 3.1062, Training Accuracy: 0.2294\n",
      "Validation Loss: 3.1998, Validation Accuracy: 0.2130\n",
      "Epoch 27:\n",
      "Training Loss: 3.0826, Training Accuracy: 0.2339\n",
      "Validation Loss: 3.0924, Validation Accuracy: 0.2372\n",
      "Epoch 28:\n",
      "Training Loss: 3.0104, Training Accuracy: 0.2438\n",
      "Validation Loss: 3.0442, Validation Accuracy: 0.2389\n",
      "Epoch 29:\n",
      "Training Loss: 2.9532, Training Accuracy: 0.2557\n",
      "Validation Loss: 3.0999, Validation Accuracy: 0.2318\n",
      "Epoch 30:\n",
      "Training Loss: 2.9301, Training Accuracy: 0.2638\n",
      "Validation Loss: 3.1089, Validation Accuracy: 0.2375\n",
      "Epoch 31:\n",
      "Training Loss: 2.9190, Training Accuracy: 0.2646\n",
      "Validation Loss: 2.9544, Validation Accuracy: 0.2696\n",
      "Epoch 32:\n",
      "Training Loss: 2.8825, Training Accuracy: 0.2695\n",
      "Validation Loss: 2.9121, Validation Accuracy: 0.2738\n",
      "Epoch 33:\n",
      "Training Loss: 2.7827, Training Accuracy: 0.2918\n",
      "Validation Loss: 2.9280, Validation Accuracy: 0.2663\n",
      "Epoch 34:\n",
      "Training Loss: 2.7578, Training Accuracy: 0.2966\n",
      "Validation Loss: 2.8464, Validation Accuracy: 0.2818\n",
      "Epoch 35:\n",
      "Training Loss: 2.7026, Training Accuracy: 0.3074\n",
      "Validation Loss: 2.8274, Validation Accuracy: 0.2902\n",
      "Epoch 36:\n",
      "Training Loss: 2.6580, Training Accuracy: 0.3175\n",
      "Validation Loss: 2.8238, Validation Accuracy: 0.2880\n",
      "Epoch 37:\n",
      "Training Loss: 2.6822, Training Accuracy: 0.3108\n",
      "Validation Loss: 2.7865, Validation Accuracy: 0.2964\n",
      "Epoch 38:\n",
      "Training Loss: 2.6099, Training Accuracy: 0.3256\n",
      "Validation Loss: 2.7588, Validation Accuracy: 0.3063\n",
      "Epoch 39:\n",
      "Training Loss: 2.5885, Training Accuracy: 0.3328\n",
      "Validation Loss: 2.7655, Validation Accuracy: 0.3041\n",
      "Epoch 40:\n",
      "Training Loss: 2.5573, Training Accuracy: 0.3370\n",
      "Validation Loss: 2.7664, Validation Accuracy: 0.3043\n",
      "Epoch 41:\n",
      "Training Loss: 2.5017, Training Accuracy: 0.3451\n",
      "Validation Loss: 2.7036, Validation Accuracy: 0.3226\n",
      "Epoch 42:\n",
      "Training Loss: 2.4739, Training Accuracy: 0.3552\n",
      "Validation Loss: 2.7680, Validation Accuracy: 0.3062\n",
      "Epoch 43:\n",
      "Training Loss: 2.4551, Training Accuracy: 0.3586\n",
      "Validation Loss: 2.7733, Validation Accuracy: 0.3055\n",
      "Epoch 44:\n",
      "Training Loss: 2.5537, Training Accuracy: 0.3405\n",
      "Validation Loss: 2.7075, Validation Accuracy: 0.3102\n",
      "Epoch 45:\n",
      "Training Loss: 2.4508, Training Accuracy: 0.3590\n",
      "Validation Loss: 2.6370, Validation Accuracy: 0.3305\n",
      "Epoch 46:\n",
      "Training Loss: 2.3667, Training Accuracy: 0.3763\n",
      "Validation Loss: 2.6764, Validation Accuracy: 0.3281\n",
      "Epoch 47:\n",
      "Training Loss: 2.3547, Training Accuracy: 0.3794\n",
      "Validation Loss: 2.6631, Validation Accuracy: 0.3284\n",
      "Epoch 48:\n",
      "Training Loss: 2.3654, Training Accuracy: 0.3765\n",
      "Validation Loss: 2.6233, Validation Accuracy: 0.3383\n",
      "Epoch 49:\n",
      "Training Loss: 2.2965, Training Accuracy: 0.3927\n",
      "Validation Loss: 2.6109, Validation Accuracy: 0.3412\n",
      "Epoch 50:\n",
      "Training Loss: 2.2392, Training Accuracy: 0.4031\n",
      "Validation Loss: 2.5801, Validation Accuracy: 0.3474\n",
      "Epoch 51:\n",
      "Training Loss: 2.1844, Training Accuracy: 0.4158\n",
      "Validation Loss: 2.5581, Validation Accuracy: 0.3506\n",
      "Epoch 52:\n",
      "Training Loss: 2.1551, Training Accuracy: 0.4212\n",
      "Validation Loss: 2.5788, Validation Accuracy: 0.3471\n",
      "Epoch 53:\n",
      "Training Loss: 2.1530, Training Accuracy: 0.4262\n",
      "Validation Loss: 2.6385, Validation Accuracy: 0.3420\n",
      "Epoch 54:\n",
      "Training Loss: 2.1699, Training Accuracy: 0.4203\n",
      "Validation Loss: 2.5596, Validation Accuracy: 0.3515\n",
      "Epoch 55:\n",
      "Training Loss: 2.1131, Training Accuracy: 0.4314\n",
      "Validation Loss: 2.5281, Validation Accuracy: 0.3629\n",
      "Epoch 56:\n",
      "Training Loss: 2.0548, Training Accuracy: 0.4432\n",
      "Validation Loss: 2.5729, Validation Accuracy: 0.3578\n",
      "Epoch 57:\n",
      "Training Loss: 2.0636, Training Accuracy: 0.4457\n",
      "Validation Loss: 2.5296, Validation Accuracy: 0.3582\n",
      "Epoch 58:\n",
      "Training Loss: 2.0420, Training Accuracy: 0.4492\n",
      "Validation Loss: 2.5452, Validation Accuracy: 0.3600\n",
      "Epoch 59:\n",
      "Training Loss: 1.9912, Training Accuracy: 0.4580\n",
      "Validation Loss: 2.5416, Validation Accuracy: 0.3650\n",
      "Epoch 60:\n",
      "Training Loss: 1.9749, Training Accuracy: 0.4660\n",
      "Validation Loss: 2.5124, Validation Accuracy: 0.3668\n",
      "Epoch 61:\n",
      "Training Loss: 1.9223, Training Accuracy: 0.4744\n",
      "Validation Loss: 2.5109, Validation Accuracy: 0.3691\n",
      "Epoch 62:\n",
      "Training Loss: 1.8808, Training Accuracy: 0.4846\n",
      "Validation Loss: 2.4940, Validation Accuracy: 0.3753\n",
      "Epoch 63:\n",
      "Training Loss: 1.8470, Training Accuracy: 0.4945\n",
      "Validation Loss: 2.5310, Validation Accuracy: 0.3672\n",
      "Epoch 64:\n",
      "Training Loss: 1.8555, Training Accuracy: 0.4900\n",
      "Validation Loss: 2.5736, Validation Accuracy: 0.3676\n",
      "Epoch 65:\n",
      "Training Loss: 1.8516, Training Accuracy: 0.4905\n",
      "Validation Loss: 2.6025, Validation Accuracy: 0.3548\n",
      "Epoch 66:\n",
      "Training Loss: 1.9350, Training Accuracy: 0.4723\n",
      "Validation Loss: 2.5140, Validation Accuracy: 0.3711\n",
      "Epoch 67:\n",
      "Training Loss: 1.8645, Training Accuracy: 0.4878\n",
      "Validation Loss: 2.5242, Validation Accuracy: 0.3719\n",
      "CPU times: user 1min 18s, sys: 10.6 s, total: 1min 28s\n",
      "Wall time: 3h 15min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python KANttention_Classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54374a4b-9f56-48c3-b3f3-d1591305c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
